{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import optax  # https://github.com/deepmind/optax\n",
    "import torch  # https://pytorch.org\n",
    "import torchvision  # https://pytorch.org\n",
    "from jaxtyping import Array, Float, Int, PyTree  # https://github.com/google/jaxtyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "from nn import Module, Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 3e-4\n",
    "STEPS = 300\n",
    "PRINT_EVERY = 30\n",
    "SEED = 5678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalise_data = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    \"MNIST\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=normalise_data,\n",
    ")\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    \"MNIST\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=normalise_data,\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "goodness: 0.0,\n",
      "trainable layers: [0, 1],\n",
      "optimizer: GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x7f1c9c9862a0>, update=<function chain.<locals>.update_fn at 0x7f1c9c984e00>),\n",
      "Layer 0: Module(\n",
      "  _layer=Linear(\n",
      "    weight=f32[1024,784],\n",
      "    bias=f32[1024],\n",
      "    in_features=784,\n",
      "    out_features=1024,\n",
      "    use_bias=True\n",
      "  ),\n",
      "  _activation=<function <lambda>>,\n",
      "  _goodness_fn=<function <lambda>>,\n",
      "  _opt_state=None,\n",
      "  _theta=1.0\n",
      "),\n",
      "Layer 1: Module(\n",
      "  _layer=Linear(\n",
      "    weight=f32[10,1024],\n",
      "    bias=f32[10],\n",
      "    in_features=1024,\n",
      "    out_features=10,\n",
      "    use_bias=True\n",
      "  ),\n",
      "  _activation=<function softmax>,\n",
      "  _goodness_fn=<function <lambda>>,\n",
      "  _opt_state=None,\n",
      "  _theta=1.0\n",
      "),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "layer1 = Module(\n",
    "    eqx.nn.Linear(\n",
    "        in_features=28*28,\n",
    "        out_features=1024,\n",
    "        key=jr.PRNGKey(SEED)\n",
    "    )\n",
    ")\n",
    "layer2 = Module(\n",
    "    eqx.nn.Linear(\n",
    "        in_features=1024,\n",
    "        out_features=10,\n",
    "        key=jr.PRNGKey(SEED)\n",
    "    ),\n",
    "    jax.nn.softmax\n",
    ")\n",
    "\n",
    "model = Network(\n",
    "    [layer1, layer2],\n",
    "    optax.adam(LEARNING_RATE)\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 28, 28)\n",
      "(1,)\n",
      "[5]\n"
     ]
    }
   ],
   "source": [
    "dummy_x, dummy_y = next(iter(trainloader))\n",
    "dummy_x = dummy_x.numpy()\n",
    "dummy_y = dummy_y.numpy()\n",
    "print(dummy_x.shape)  # BATCH_SIZEx1x28x28\n",
    "print(dummy_y.shape)  # BATCH_SIZE\n",
    "print(dummy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_y_on_x(x: Array, y: Array):\n",
    "    \"\"\"\n",
    "    Replace the first 10 pixels of data [x] with one-hot-encoded label [y]\n",
    "    \"\"\"\n",
    "    x_ = jnp.ravel(x)\n",
    "    x_ = x_.at[:10].set(jnp.zeros((10,)))\n",
    "    x_ = x_.at[y.item()].set(1)\n",
    "\n",
    "    return x_.reshape(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy_x_p = overlay_y_on_x(np.squeeze(dummy_x), dummy_y)\n",
    "dummy_x_n = overlay_y_on_x(np.squeeze(dummy_x), 9 - dummy_y) # arbitrary but incorrect label\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.imshow(dummy_x_p)\n",
    "ax.set_title(\"Correct label\")\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.imshow(dummy_x_n)\n",
    "ax.set_title(\"Incorrect label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: p(positive)=0.3296\n",
      "Step 0: p(negative)=0.3842\n",
      "Step 30: p(positive)=0.3278\n",
      "Step 30: p(negative)=0.3495\n",
      "Step 60: p(positive)=0.3192\n",
      "Step 60: p(negative)=0.3338\n",
      "Step 90: p(positive)=0.3147\n",
      "Step 90: p(negative)=0.3357\n",
      "Step 120: p(positive)=0.3167\n",
      "Step 120: p(negative)=0.3286\n",
      "Step 150: p(positive)=0.3124\n",
      "Step 150: p(negative)=0.3237\n",
      "Step 180: p(positive)=0.3059\n",
      "Step 180: p(negative)=0.3185\n",
      "Step 210: p(positive)=0.3017\n",
      "Step 210: p(negative)=0.3142\n",
      "Step 240: p(positive)=0.3106\n",
      "Step 240: p(negative)=0.3207\n",
      "Step 270: p(positive)=0.3007\n",
      "Step 270: p(negative)=0.3091\n"
     ]
    }
   ],
   "source": [
    "# train the first layer\n",
    "for i in range(STEPS):\n",
    "    x, y = next(iter(trainloader))\n",
    "    x = x.numpy()\n",
    "    y = y.numpy()\n",
    "\n",
    "    x_p = overlay_y_on_x(np.squeeze(x), y)\n",
    "    x_n = overlay_y_on_x(np.squeeze(x), 9 - y)\n",
    "\n",
    "    p_p, _, _ = model.train_layer(0, np.ravel(x_p), True)\n",
    "    p_n, _, _ = model.train_layer(0, np.ravel(x_n), False)\n",
    "\n",
    "    if i % PRINT_EVERY == 0:\n",
    "        print(f\"Step {i}: p(positive)={p_p:.4f}\")\n",
    "        print(f\"Step {i}: p(negative)={p_n:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: p(positive)=0.2710\n",
      "Step 0: p(negative)=0.2710\n",
      "Step 30: p(positive)=0.2709\n",
      "Step 30: p(negative)=0.2709\n",
      "Step 60: p(positive)=0.2709\n",
      "Step 60: p(negative)=0.2709\n",
      "Step 90: p(positive)=0.2710\n",
      "Step 90: p(negative)=0.2710\n",
      "Step 120: p(positive)=0.2709\n",
      "Step 120: p(negative)=0.2709\n",
      "Step 150: p(positive)=0.2711\n",
      "Step 150: p(negative)=0.2711\n",
      "Step 180: p(positive)=0.2710\n",
      "Step 180: p(negative)=0.2710\n",
      "Step 210: p(positive)=0.2710\n",
      "Step 210: p(negative)=0.2710\n",
      "Step 240: p(positive)=0.2710\n",
      "Step 240: p(negative)=0.2710\n",
      "Step 270: p(positive)=0.2710\n",
      "Step 270: p(negative)=0.2710\n"
     ]
    }
   ],
   "source": [
    "# train the second layer\n",
    "for i in range(STEPS):\n",
    "    x, y = next(iter(trainloader))\n",
    "    x = x.numpy()\n",
    "    y = y.numpy()\n",
    "\n",
    "    x_p = overlay_y_on_x(np.squeeze(x), y)\n",
    "    x_n = overlay_y_on_x(np.squeeze(x), 9 - y)\n",
    "\n",
    "    x_p = model.layers[0].forward(np.ravel(x_p))\n",
    "    x_n = model.layers[0].forward(np.ravel(x_n))\n",
    "\n",
    "    p_p, _, _ = model.train_layer(1, np.ravel(x_p), True)\n",
    "    p_n, _, _ = model.train_layer(1, np.ravel(x_n), False)\n",
    "\n",
    "    if i % PRINT_EVERY == 0:\n",
    "        print(f\"Step {i}: p(positive)={p_p:.4f}\")\n",
    "        print(f\"Step {i}: p(negative)={p_n:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
